<!DOCTYPE html>
<html>
  <head>
    <title> Daniel Barter - quantum particles in a zero dimensional space</title>
    <link href="../../style.css" rel="stylesheet">

    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    <script src="mix.js"></script>

  </head>
  <body>

      <nav>
        <a href="../../"> HOME </a>
        <span> / </span>
        <a href="../../CV.html"> CV </a>
        <span> / </span>
        <a href="../../blog.html"> BLOG </a>
        <span> / </span>
        <a href="../../mix.html"> MIX1010 </a> 
      </nav>

    <h1 id="quantum-particles-in-a-zero-dimensional-space">Quantum Particles in a Zero Dimensional Space</h1>
<p>Most introductory textbooks on quantum mechanics start by studying a quantum particle in the real line. In this blog post, we are going to think about quantum particles in a finite set.</p>
<h3 id="classical-mechanics-in-a-finite-set">Classical Mechanics in a finite set</h3>
<p>In classical mechanics, particles are modeled as elements of the ambient space which move continuously as a function of time. When the ambient space is a finite set <span class="math inline">\(S\)</span>, the particle <span class="math inline">\(x_t \in S\)</span> is fixed in its initial state <span class="math inline">\(x_0\)</span> for all time. This is because the only continuous maps from the interval to a finite set are constant. If <span class="math inline">\(f : S \to \mathbb{R}\)</span> is an observable, every time we measure <span class="math inline">\(f\)</span>, we record the value <span class="math inline">\(f(x_0)\)</span>. As you can see classical mechanics in a finite set is pretty boring.</p>
<h3 id="statistical-mechanics-in-a-finite-set">Statistical Mechanics in a finite set</h3>
<p>In statistical mechanics, particles are modeled as random variables <span class="math inline">\(X\)</span> taking values in the ambient space <span class="math inline">\(S\)</span>. When <span class="math inline">\(S\)</span> is a finite set, a random variable <span class="math inline">\(X \in S\)</span> is specified by its distribution function <span class="math display">\[p \in \Delta = \{ p_s  \in {\rm maps}(S,\mathbb{R}) : \sum_s p_s = 1, \; p_s \geq 0 \}.\]</span> If <span class="math inline">\(f : S \to \mathbb{R}\)</span> is an observable, when we measure <span class="math inline">\(f\)</span> we record the value <span class="math inline">\(f(s)\)</span> with probability <span class="math inline">\(p_s\)</span>. Now suppose that we actually measure <span class="math inline">\(f\)</span> and record the value <span class="math inline">\(\lambda\)</span>. Then according to Bayes rule, the state <span class="math inline">\(X\)</span> is updated: <span class="math display">\[{\bf P}(X = s | f(X) = \lambda) \propto {\bf P}(f(X) = \lambda | X = s) p_s =
\begin{cases}
p_s &amp; f(s) = \lambda \\
0 &amp; {\rm otherwise}
\end{cases}\]</span> In words, when we record <span class="math inline">\(\lambda\)</span> we truncate the probability of any incompatible state to zero and then scale the resulting vector so it becomes a probability distribution. As you can see, measurement is much more interesting in statistical mechanics. Now lets talk about dynamics. In physics, we want the time evolution of our system to be deterministic. Therefore we can model the passage of time as a function <span class="math display">\[E_t : \Delta \to \Delta\]</span> Moreover, we want the system to be invariant under time translation which implies that <span class="math display">\[E_{t+s} = E_t \circ E_s.\]</span> From the laws of probability theory, we have <span class="math display">\[{\bf P}(E_t X = s') = \sum_s {\bf P}(E_t X = s' | X = s) p_s\]</span> which implies that <span class="math display">\[E_t p = \sum_s p_s E_t \delta_s.\]</span> where <span class="math inline">\(\delta_s\)</span> is the probability distribution concentrated at <span class="math inline">\(s\)</span>. It follows that <span class="math inline">\(E_t\)</span> is linear. Any linear map which preserves <span class="math inline">\(\Delta\)</span> must have all positive real entries and columns summing to one. From Lie theory, we know that <span class="math display">\[E_t = \exp(tH)\]</span> where <span class="math inline">\(H\)</span> is a matrix whose off diagonal entries are positive with columns summing to zero. We call <span class="math inline">\(H\)</span> the Hamiltonian generator for the statistical mechanical system. One of the fundamental concepts in statistical mechanics is entropy: <span class="math display">\[\Theta= \sum_s p_s \log p_s\]</span> We would like to understand how <span class="math inline">\(\Theta\)</span> behaves under time evolution. We have <span class="math display">\[E_t p = p + tHp + O(t^2)\]</span> which implies that the directional derivative is <span class="math display">\[d\Theta(Hp).\]</span> The exterior derivative is <span class="math display">\[d\Theta = \sum_s (\log p_s + 1)dp_s\]</span> which implies that <span class="math display">\[d\Theta(Hp) = (\log p^T) H p.\]</span> Regardless of <span class="math inline">\(H\)</span>, this directional derivative is <span class="math inline">\(0\)</span> when <span class="math inline">\(p\)</span> is uniform. The uniform distribution is the maximum entropy distribution on a finite set, therefore we have proved that if the statistical mechanical system ever reaches maximum entropy, it remains there for the rest of time.</p>
<h3 id="quantum-mechanics-in-a-finite-set">Quantum Mechanics in a finite set</h3>
<p>Somewhat surprisingly, the transition from classical mechanical systems to quantum mechanical systems requires little effort. Now the state of the system is encoded using a wave function. When <span class="math inline">\(S\)</span> is a finite set, the wave function <span class="math inline">\(\chi\)</span> lives in <span class="math display">\[\{ \chi \in {\rm maps}(S,\mathbb{C}) : \langle \chi,\chi \rangle = 1\}\]</span> where <span class="math inline">\(\langle \cdot,\cdot \rangle\)</span> is the standard Hermitian form, and <span class="math inline">\({\rm maps}(S,\mathbb{C})\)</span> is the vector space with basis <span class="math inline">\(S\)</span>. We call <span class="math inline">\(S\)</span> the <strong>computation basis</strong> and denote the basis vectors by <span class="math inline">\(|s\rangle\)</span> as is traditional in quantum mechanics. If <span class="math inline">\(f : S \to \mathbb{R}\)</span> is an observable, when we measure <span class="math inline">\(f\)</span>, we record the value <span class="math inline">\(f(s)\)</span> with probability <span class="math inline">\(\lvert \chi_s \lvert^2\)</span>. If we actually measure <span class="math inline">\(f\)</span> and record <span class="math inline">\(\lambda\)</span>, the wave function collapses according to Bayes rule. The time evolution operator <span class="math inline">\(E_t\)</span> must be unitary to preserve probability, so the infinitesimal generator <span class="math inline">\(H\)</span> is skew Hermitian. This implies that time evolution is invertible. As a result we can talk about generalized observables. Choose an orthonormal basis <span class="math inline">\(\psi_i\)</span> and let <span class="math inline">\(U\)</span> be the unitary operator which takes <span class="math inline">\(\psi_i\)</span> to a computation basis vector. Then we can perform the operation <span class="math display">\[U^{-1} \circ {\rm measurement} \circ U\]</span> The spectral theorem says that a hermitian operator can be diagonalized by a unitary matrix and has real eigenvalues. Therefore, we can identify generalized observables with hermitian operators. This is one of the fundamental principles of quantum mechanics.</p>

  </body>
</html>
