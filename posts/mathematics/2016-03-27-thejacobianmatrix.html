<!DOCTYPE html>
<html>
  <head>
    <title> Daniel Barter - the jacobian matrix</title>
    <link href="../../style.css" rel="stylesheet">

    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  </head>
  <body>
    <nav>
<a href="../../"> HOME </a>
<span> / </span>
<a href="../../CV.html"> CV </a>
<span> / </span>
<a href="../../publickey.html"> PUBKEY </a>
<span> / </span>
<a href="../../blog.html"> BLOG </a>
<span> / </span>
<a href="../../mix.html"> MIX1010 </a>
<span> / </span>
<a href="../../tableau.html"> TABLEAU </a>
</nav>

<h1 id="the-jacobian-matrix">The Jacobian Matrix</h1>
<p>In the <a href="2016-02-28-thetangentbundle.html">last post</a>, we defined the tangent bundle. We have finally developed enough machinery to start seriously doing calculus on manifolds. In this post, we shall define the derivative of a smooth map between manifolds and translate the <a href="https://en.wikipedia.org/wiki/Implicit_function_theorem">implicit function theorem</a> into the language of differential geometry.</p>
<h3 id="pulling-back-vector-bundles">Pulling back vector bundles</h3>
<p>Suppose that <span class="math inline">\(f : X \to Y\)</span> is a smooth map between manifolds and <span class="math inline">\(E\)</span> is a vector bundle on <span class="math inline">\(Y\)</span>. Then we can construct the pullback vector bundle <span class="math inline">\(f^*E\)</span> on <span class="math inline">\(X\)</span>. The fiber over <span class="math inline">\(x \in X\)</span> is <span class="math inline">\((f^*E)_x = E_{f(x)}\)</span>. This describes <span class="math inline">\(f^*E\)</span> as a set. If <span class="math inline">\((\phi_{\beta\alpha})\)</span> is gluing data for <span class="math inline">\(E\)</span>, then <span class="math inline">\((\phi_{\beta\alpha} \circ f)\)</span> is gluing data for <span class="math inline">\(f^*E\)</span>. This describes <span class="math inline">\(f^* E\)</span> as a vector bundle. We can also realize the pullback bundle <span class="math inline">\(f^*E\)</span> as the following <a href="https://en.wikipedia.org/wiki/Pullback_%28category_theory%29">fibered product</a>: <span class="math display">\[\require{AMScd}
\begin{CD}
f^* E @&gt;&gt;&gt; E;\\
@VVV @V{\pi}VV \\
X @&gt;{f}&gt;&gt; Y;
\end{CD}\]</span> This universal property tells us how to define smooth maps into the vector bundle <span class="math inline">\(f^*E\)</span>. Once we have developed more abstract sheaf theory, we will see a nice description for the sheaf of sections of <span class="math inline">\(f^* E\)</span>, but we do not need it to talk about the Jacobian matrix.</p>
<h3 id="the-derivative-of-a-smooth-map">The derivative of a smooth map</h3>
<p>Suppose that <span class="math inline">\(f : X \to Y\)</span> is a smooth map between manifolds and <span class="math inline">\(D \in T_pX\)</span> is a differential operator. Define <span class="math inline">\((f'D)(g) = D(g \circ f)\)</span> where <span class="math inline">\(g \in \mathscr{C}_{Y,f(p)}\)</span>. Then <span class="math inline">\(f' D \in T_{f(p)}Y\)</span>. If we represent tangent vectors as equivalence classes of curves <span class="math inline">\([\gamma(t)]\)</span>, then <span class="math inline">\(f'[\gamma(t)] = [f \circ \gamma(t)]\)</span>. The maps <span class="math inline">\(f' : T_p X \to T_{f(p)}Y\)</span> are linear and they assemble to form a vector bundle homomorphism <span class="math inline">\(f' : TX \to f^* TY\)</span> which is called the <strong>derivative</strong> of <span class="math inline">\(f\)</span>. If <span class="math inline">\(x_1,\dots,x_m\)</span> are coordinates around <span class="math inline">\(p\)</span> and <span class="math inline">\(y_1,\dots,y_n\)</span> are coordinates around <span class="math inline">\(f(p)\)</span>, then <span class="math inline">\(f\)</span> can be written in the form <span class="math inline">\(y_i = f_i(x_1,\dots,x_m)\)</span>. This implies that <span class="math display">\[f' = \left( \frac{\partial f_i}{\partial x_j} \right)\]</span> with respect to the frames <span class="math inline">\((\partial / \partial x_j)\)</span>, <span class="math inline">\((\partial / \partial y_i)\)</span> of <span class="math inline">\(TX\)</span> and <span class="math inline">\(TY\)</span> respectively. This is the the <a href="https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant">Jacobian matrix</a>.</p>
<h3 id="the-inverse-function-theorem">The Inverse Function Theorem</h3>
<p>Suppose that <span class="math inline">\(f : X \to Y\)</span> is a smooth map with derivative <span class="math inline">\(f' : TX \to f^* TY\)</span>. The <a href="https://en.wikipedia.org/wiki/Inverse_function_theorem">inverse function theorem</a> says that if <span class="math inline">\(p \in X\)</span> and <span class="math inline">\(f'_p\)</span> is an isomorphism, then there are neighborhoods <span class="math inline">\(p \in U\)</span> and <span class="math inline">\(f(p) \in V\)</span> such that <span class="math inline">\(U \subseteq f^{-1}(V)\)</span> and <span class="math inline">\(f : U \to V\)</span> is a diffeomorphism. The inverse function theorem is plausible: If you take <span class="math inline">\(p \in X\)</span> and start zooming in around <span class="math inline">\(p\)</span>, the smooth map <span class="math inline">\(f\)</span> starts to look like the linear map <span class="math inline">\(f'_p\)</span>. Once you have zoomed in to inspect an extremely small open neighborhood around <span class="math inline">\(p\)</span>, <span class="math inline">\(f\)</span> and <span class="math inline">\(f'_p\)</span> are indistinguishable to the naked eye, so you expect <span class="math inline">\(f\)</span> to be invertible on this open neighborhood.</p>
<p>Let's try and make this rigorous. Since <span class="math inline">\(f'_p\)</span> is invertible and the determinant not vanishing is an open condition, we can choose open neighborhoods <span class="math inline">\(p \in U\)</span> and <span class="math inline">\(f(p) \in V\)</span> such that <span class="math inline">\(f(U) \subseteq V\)</span> and <span class="math inline">\(f' : TU \to f^*TV\)</span> is an isomorphism. By shrinking these open neighborhoods, we can assume that <span class="math inline">\(U = \mathbb{R}^d\)</span>, <span class="math inline">\(V = \mathbb{R}^d\)</span> and both <span class="math inline">\(p,f(p)\)</span> are equal to zero in their respective coordinate charts. Now <span class="math inline">\(f\)</span> is a smooth map <span class="math inline">\(\mathbb{R}^d \to \mathbb{R}^d\)</span> sending <span class="math inline">\(0\)</span> to <span class="math inline">\(0\)</span> and <span class="math inline">\(f' : \mathbb{R}^d \to {\rm GL}_d(\mathbb{R})\)</span>. We want to construct a germ <span class="math inline">\(g\)</span> around <span class="math inline">\(0 \in \mathbb{R}^d\)</span> taking values in <span class="math inline">\(\mathbb{R}^d\)</span> such that</p>
<ul>
<li><span class="math inline">\(fg = gf = {\rm id}\)</span></li>
<li><span class="math inline">\(g' = (f')^{-1}\)</span></li>
</ul>
<p>in the stalk. This is an example of an <strong>integrability problem</strong>. Integrability problems are the heart of differential geometry and we will see many examples later. Proving the inverse function theorem is equivalent to solving this integrability problem. If you want to solve integrability problems, you need to use advanced tools from analysis. Many famous open problems in differential geometry can be translated into integrability problems (for example, the existence of a complex structure on the 6-sphere).</p>
<h3 id="the-implicit-function-theorem">The Implicit Function Theorem</h3>
<p>Let <span class="math inline">\(f : X \to Y\)</span> be a smooth map whose derivative has constant rank <span class="math inline">\(r\)</span>. Fix <span class="math inline">\(p \in X\)</span>. Choose coordinates <span class="math inline">\(x_1,\dots,x_m\)</span> on <span class="math inline">\(p \in U\)</span> and <span class="math inline">\(y_1,\dots,y_n\)</span> on <span class="math inline">\(f(p) \in V\)</span> such that <span class="math inline">\(f(U) \subseteq V\)</span> and <span class="math display">\[A = \left( \frac{\partial f_i}{\partial x_j} \right)_{i,j = 1,\dots,r}\]</span> is invertible at <span class="math inline">\(p\)</span>. Since invertibility is an open condition, we can shrink <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span> so that the minor <span class="math inline">\(A\)</span> is invertible on all of <span class="math inline">\(U\)</span>. Consider the map <span class="math inline">\(\Phi : U \to \mathbb{R}^m\)</span> defined by <span class="math inline">\(\Phi = (f_1,\dots,f_r,x_{r+1},\dots,x_m)\)</span>. The derivative is given by <span class="math display">\[\Phi' = \begin{pmatrix} A &amp; * \\ 0 &amp; I \end{pmatrix}\]</span> By shrinking <span class="math inline">\(U\)</span>, the inverse function theorem implies that <span class="math inline">\(\Phi\)</span> becomes a diffeomorphism onto its image, which implies that <span class="math inline">\(f_1,\dots,f_r,x_{r+1},\dots,x_m\)</span> are coordinates on <span class="math inline">\(p \in U\)</span>. With respect to these new coordinates, <span class="math inline">\(f\)</span> is given by <span class="math display">\[
\begin{split}
&amp;y_1 = f_1 \\
&amp;y_2 = f_2 \\
&amp;\cdots \\
&amp;y_r = f_r \\
&amp;y_{r+1} = g_{r+1}(f_1,\dots,f_r,x_{r+1},\dots,x_m) \\
&amp;y_{r+2} = g_{r+2}(f_1,\dots,f_r,x_{r+1},\dots,x_m) \\
&amp;\cdots \\
&amp;y_{n} = g_{n}(f_1,\dots,f_r,x_{r+1},\dots,x_m) \\
\end{split}
\]</span> and the derivative is given by <span class="math display">\[f' = \begin{pmatrix} I &amp; 0 \\ * &amp; B \end{pmatrix}\]</span> Since <span class="math inline">\(f'\)</span> has constant rank <span class="math inline">\(r\)</span>, the matrix <span class="math inline">\(B\)</span> must be zero, which implies that each <span class="math inline">\(g_j\)</span> does not depend on <span class="math inline">\(x_{r+1},\dots,x_m\)</span>. Consider the map <span class="math inline">\(\Psi : V \to \mathbb{R}^n\)</span> defined by <span class="math display">\[\Psi = 
(y_1,\dots,y_r,w_{r+1} = y_{r+1}-g_{r+1}(y_1,\dots,y_r),\dots,w_n = y_n-g_n(y_1,\dots,y_r)).\]</span> Its derivative is <span class="math display">\[\Psi' = \begin{pmatrix} I &amp; 0 \\ * &amp; I \end{pmatrix}\]</span> which is invertible, therefore by shrinking <span class="math inline">\(U\)</span> and <span class="math inline">\(V\)</span>, <span class="math inline">\(y_1,\dots,y_r,w_{r+1},\dots,w_{n}\)</span> is a coordinate chart on <span class="math inline">\(V\)</span>. With respect to the coordinate chart <span class="math inline">\((f_1,\dots,f_r,x_{r+1},\dots,x_m)\)</span> on <span class="math inline">\(U\)</span> and <span class="math inline">\((y_1,\dots,y_r,w_{r+1},\dots,w_n)\)</span> on <span class="math inline">\(V\)</span>, <span class="math inline">\(f\)</span> is given by the following linear map: <span class="math display">\[\begin{pmatrix} I &amp; 0 \\ 0 &amp; 0 \end{pmatrix}\]</span> This result is often called the implicit function theorem or the rank theorem. It tells us that <span class="math inline">\(x_{r+1},\dots,x_m\)</span> are coordinates around <span class="math inline">\(p\)</span> in <span class="math inline">\(f^{-1}(f(p))\)</span>. The implicit function theorem is best demonstrated with a simple example: Consider the map <span class="math inline">\(f : \mathbb{R}^2 \to \mathbb{R}\)</span> defined by <span class="math inline">\(f(x,y) = x^2 + y^2\)</span>. The derivative is given by <span class="math display">\[f' = \begin{pmatrix} 2x &amp; 2y \end{pmatrix}\]</span> which implies that <span class="math inline">\(f : \mathbb{R}^2 \backslash \{ 0 \} \to \mathbb{R}\)</span> has constant rank <span class="math inline">\(1\)</span>. Consider the point <span class="math inline">\((1,0)\)</span>. The jacobian at this point is <span class="math inline">\(\begin{pmatrix} 2 &amp; 0 \end{pmatrix}\)</span>. Therefore <span class="math inline">\(y\)</span> is a coordinate on <span class="math inline">\(f^{-1}(1) = \{ (x,y) : x^2 + y^2 = 1 \}\)</span> in a neighborhood of <span class="math inline">\((1,0)\)</span>. This is easy to see geometrically:</p>
<div class="figure">
<img src="../../img/2016-03-27-implicitfunctionthmcoordinatechart.PNG" />

</div>
<p>Despite the simplicity of this example, it really captures what is going on. The implicit function theorem allows us to locally realize fibers of smooth maps as graphs. Similarly, <span class="math inline">\(x\)</span> is a coordinate on <span class="math inline">\(\{ (x,y) : x^2 + y^2 = 1 \}\)</span> in some neighborhood of <span class="math inline">\((0,1)\)</span>. These two coordinate charts intersect in the first quadrant and on the intersection, <span class="math inline">\(y = \sqrt{1-x^2}\)</span>.</p>
<p>A very similar argument proves that <span class="math inline">\(x,y\)</span> are coordinates around <span class="math inline">\((0,0,1)\)</span> on the 2-sphere <span class="math inline">\(S^2 = \{ (x,y,z) : x^2 + y^2 + z^2 = 1 \}\)</span>.</p>
<div class="figure">
<img src="../../img/2016-03-27-spherenorthpolechart.PNG" />

</div>
<p>Now consider the function <span class="math inline">\(z : S^2 \to \mathbb{R}\)</span> which gives the height above the <span class="math inline">\(x,y\)</span>-plane. In a neighbourhood of <span class="math inline">\((0,0,1)\)</span>, we have <span class="math inline">\(z = \sqrt{1-x^2-y^2}\)</span>. The derivative of <span class="math inline">\(z\)</span> is <span class="math display">\[z' = \left(\frac{-x}{\sqrt{1-x^2-y^2}},\frac{-y}{\sqrt{1-x^2-y^2}}\right)\]</span> Therefore, <span class="math inline">\(z\)</span> has rank <span class="math inline">\(0\)</span> at <span class="math inline">\((0,0,1)\)</span> and rank <span class="math inline">\(1\)</span> in the rest of the neighborhood of <span class="math inline">\((0,0,1)\)</span>. Notice that <span class="math inline">\(z^{-1}(1)\)</span> is <span class="math inline">\(0\)</span>-dimensional and <span class="math inline">\(z^{-1}(1-\epsilon)\)</span> is <span class="math inline">\(1\)</span> dimensional. This shows that the constant rank hypothesis we used to prove the implicit function theorem is necessary.</p>
<h3 id="exercises">Exercises</h3>
<ul>
<li>Let <span class="math inline">\(A\)</span> be a matrix. What is the jacobian of <span class="math inline">\(x \mapsto Ax + b\)</span>?</li>
<li>Using the implicit function theorem, carefully construct coordinates on <span class="math display">\[S^n = \{ 
(x_0,x_1,\dots,x_n) : x_0^2 + \dots + x_n^2 = 1 \}\]</span></li>
<li>when is the solution set of a polynomial <span class="math inline">\(f(x_1,\dots,x_n)\)</span> a smooth manifold?</li>
<li><strong>(Harder)</strong> Compute the Jacobian of the determinant map <span class="math inline">\({\rm det} : {\rm GL}_n(\mathbb{R}) \to \mathbb{R}^{\times}\)</span>.</li>
</ul>


  </body>
</html>
